# Stream C: Extraction Quality Audit

**Date:** 2026-02-07  
**World Model:** `output/world_model.json`

## Summary Statistics

| Metric | Count |
|--------|-------|
| Total entities | 1,057 |
| Total transitions | 2,278 |
| Total relationships | 1,187 |

## Entity Type Distribution

| Type | Count | % of Total |
|------|-------|------------|
| concept | 269 | 25.4% |
| tool | 237 | 22.4% |
| project | 232 | 21.9% |
| decision | 154 | 14.6% |
| organization | 86 | 8.1% |
| belief | 42 | 4.0% |
| person | 31 | 2.9% |
| period | 6 | 0.6% |
| **event** | **0** | **0.0%** |

## üö® Critical Issues

### 1. Zero Event Entities

**This is the most critical finding.** The extraction pipeline produced exactly **0 event entities**.

Events are the backbone of temporal retrieval ‚Äî meetings, conversations, trips, purchases, decisions made on specific days. Without events, temporal queries like "what did I do last Tuesday" or "when did I meet X" are impossible.

### 2. Zero Temporal Bounding

| Temporal Field | Entities with Field |
|----------------|---------------------|
| `valid_from` | 0 (0%) |
| `valid_to` | 0 (0%) |
| `date` in current_state | 0 (0%) |
| Any date-like field in state | 40 (3.8%) |

The only temporal information exists in:
- 6 `period` entities with loose timeframe descriptions ("Summer 2025", "mid-August")
- 40 entities with date-adjacent fields (e.g., "timing", "timeframe" as free text)

### 3. Transitions Lack Event Timestamps

| Transition Field | Count |
|------------------|-------|
| `timestamp` (extraction time) | 2,278 (100%) |
| `occurred_at` (actual event time) | 0 (0%) |

Transitions record *when they were extracted* (all batch-processed at ~1735910689), not *when the events actually happened*.

### 4. Entity Type Imbalance

**Nearly half of all entities (47.8%) are concepts + tools.**

Sample concepts (likely noise for personal retrieval):
- `ThreadPoolExecutor-based parallelization`
- `scroll-triggered slide-in popup`
- `YouTube channel URL format`

Sample tools:
- `Deepseek (deepseek-chat / v3)`
- `Framer`
- `TensorFlow / Keras`

These are useful for "what tools do I use" queries but add noise for temporal/personal queries.

## Relationship Analysis

| Relationship Type | Count |
|-------------------|-------|
| related_to | 323 |
| uses | 281 |
| part_of | 193 |
| works_on | 147 |
| integrates_with | 139 |
| caused_by | 50 |
| collaborates_with | 29 |
| during | 13 |
| replaces | 12 |

Only 13 `during` relationships could provide temporal context.

## Period Entities (The Only Temporal Anchors)

These 6 entities are the only temporal structure:

1. **Moving to San Francisco** - "soon"
2. **SF relocation / networking phase** - Union Square hotel, scouting
3. **SF gap semester** - Duboce Triangle
4. **Gap semester (UMD) ‚Äî SF period** - "Now ‚Äî mid-August 2025"
5. **Summer 2025 internship at Planted Solar** - "Summer 2025"
6. **Spring 2025 gap semester** - active period

## Impact on Retrieval Experiment

### What This Means for Temporal Retrieval

| Query Type | Expected Performance |
|------------|---------------------|
| "What happened on [date]?" | ‚ùå Will fail - no dated events |
| "When did I [action]?" | ‚ùå Will fail - no event timestamps |
| "What was I working on during [period]?" | ‚ö†Ô∏è May partially work via period entities |
| "What tools do I use for X?" | ‚úÖ Should work - many tool/concept entities |
| "Who do I know at [org]?" | ‚ö†Ô∏è Limited - only 31 person entities |

### Root Causes to Investigate

1. **Extraction prompt may not emphasize events** - LLM might be biased toward extracting concepts/definitions over happenings
2. **Source documents may lack explicit dates** - Chat logs might not have clear temporal markers
3. **No date inference from file metadata** - Not using file modification times or conversation timestamps
4. **Entity type schema may be missing "event"** - Need to check if event is even a valid type in the extraction schema

## Recommendations

### Immediate (for this experiment)
- Document that temporal retrieval baseline will be near-zero
- Focus comparison on semantic/conceptual queries instead
- Note extraction quality as a confounding variable

### For Pipeline Improvement
1. **Add explicit "event" type to schema** with required `date` field
2. **Pass source document timestamps** to extraction for date inference
3. **Tune extraction prompt** to prioritize temporal information
4. **Consider separate event extraction pass** focused on actions/happenings
5. **Filter or deprioritize** generic concepts/tools during retrieval

---

*Generated by Stream C extraction audit*
